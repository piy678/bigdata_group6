{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dbb365a-59a0-43e6-a493-dadc874bb72c",
   "metadata": {},
   "source": [
    "# Web Scraping Exercise\n",
    "\n",
    "Web Scraping allows you to gather large volumes of data from diverse and real-time online sources. This data can be crucial for enriching your datasets, filling in gaps, and providing current information that enhances the quality and relevance of your analysis. Web scraping enables you to collect data that might not be readily available through traditional APIs or databases, offering a competitive edge by incorporating unique and comprehensive insights. Moreover, it automates the data collection process, saving time and resources while ensuring a scalable approach to continuously updating and maintaining your datasets.\n",
    "\n",
    "Ethical web scraping involves respecting website terms of service, avoiding overloading servers, and ensuring that the collected data is used responsibly and in compliance with privacy laws and regulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588254e6-2157-47bd-b21e-9c55888b654d",
   "metadata": {},
   "source": [
    "Use Python, ```requests```, ```BeautifulSoup``` and/or ```pandas``` to scrape web data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ef6a9f-888c-4b46-839f-e6c2055a3b44",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "afe18cce-f661-44e3-966a-f6253025b02a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T20:10:36.070159Z",
     "start_time": "2025-06-15T20:10:34.490752Z"
    }
   },
   "source": [
    "# TODO\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "6df7c955-ae58-4fb4-9e77-fa945b5a2d0e",
   "metadata": {},
   "source": [
    "## Define the Target URL"
   ]
  },
  {
   "cell_type": "code",
   "id": "c6227173-b844-4330-ab17-fc4ed20c546c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T20:10:54.516890Z",
     "start_time": "2025-06-15T20:10:54.501100Z"
    }
   },
   "source": [
    "#url = # TODO\n",
    "url = 'https://www.billboard.com/charts/hot-100/'\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "e0aa53df-3c02-43b4-8810-aaac3a0685ab",
   "metadata": {},
   "source": [
    "## Send a Request to the Website\n",
    "\n",
    "Do not forget to check the response status code"
   ]
  },
  {
   "cell_type": "code",
   "id": "cd7ee575-a612-410c-8d4b-0d201e220eb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T20:10:59.874364Z",
     "start_time": "2025-06-15T20:10:58.708123Z"
    }
   },
   "source": [
    "# TODO\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Anfrage erfolgreich!\")\n",
    "else:\n",
    "    print(f\"Anfrage fehlgeschlagen mit Statuscode {response.status_code}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anfrage erfolgreich!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "7fc3ab17-c3a3-4886-a600-54ff193ea1f8",
   "metadata": {},
   "source": [
    "## Parse the HTML Content\n",
    "\n",
    "Use a library to access the HTMl content"
   ]
  },
  {
   "cell_type": "code",
   "id": "fb23d1a5-ef0e-4512-b31e-a37a83a2effe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T20:11:04.732798Z",
     "start_time": "2025-06-15T20:11:03.944316Z"
    }
   },
   "source": [
    "# TODO\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "c7cbb259-602c-4644-a9ac-41d8a7fe0eb3",
   "metadata": {},
   "source": [
    "## Identify the Data to be Scraped\n",
    "\n",
    "Write a couple of sentence on the data you want to scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dde90e0-854f-4053-8362-c885e2c5e457",
   "metadata": {},
   "source": [
    "TODO: \n",
    "Daten von der Billboard Hot 100 Website werden gescrapt. Ziel ist es, Songtitel, Interpreten und Platzierungen der w√∂chentlichen Charts zu extrahieren. Diese Informationen sollen mit Spotify-Merkmalen verglichen werden, um Merkmale erfolgreicher Songs zu analysieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eb64f4-3159-4782-9425-efbec82b7592",
   "metadata": {},
   "source": [
    "## Extract Data\n",
    "\n",
    "Find specific elements and extract text or attributes from elements (handle pagination if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "id": "67076819-665f-43c6-9811-1218696a1b88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T20:15:24.161504Z",
     "start_time": "2025-06-15T20:15:22.839738Z"
    }
   },
   "source": [
    "# TODO\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.billboard.com/charts/hot-100\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "songs = []\n",
    "\n",
    "for entry in soup.select(\"li.o-chart-results-list__item\"):\n",
    "    title_tag = entry.find(\"h3\")\n",
    "    artist_tag = entry.find(\"span\")\n",
    "\n",
    "    if title_tag and artist_tag:\n",
    "        title = title_tag.get_text(strip=True)\n",
    "        artist = artist_tag.get_text(strip=True)\n",
    "\n",
    "        songs.append({\n",
    "            'Title': title,\n",
    "            'Artist': artist\n",
    "        })\n",
    "\n",
    "\n",
    "for song in songs[:10]:\n",
    "    print(song)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': 'Ordinary', 'Artist': 'Alex Warren'}\n",
      "{'Title': 'What I Want', 'Artist': 'Morgan Wallen Featuring Tate McRae'}\n",
      "{'Title': 'Just In Case', 'Artist': 'Morgan Wallen'}\n",
      "{'Title': 'Luther', 'Artist': 'Kendrick Lamar & SZA'}\n",
      "{'Title': \"I'm The Problem\", 'Artist': 'Morgan Wallen'}\n",
      "{'Title': 'A Bar Song (Tipsy)', 'Artist': 'Shaboozey'}\n",
      "{'Title': 'Die With A Smile', 'Artist': 'Lady Gaga & Bruno Mars'}\n",
      "{'Title': 'Lose Control', 'Artist': 'Teddy Swims'}\n",
      "{'Title': 'Beautiful Things', 'Artist': 'Benson Boone'}\n",
      "{'Title': 'Nokia', 'Artist': 'Drake'}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "15439eda-7402-41f6-9322-2ddecf24bf91",
   "metadata": {},
   "source": [
    "## Store Data in a Structured Format\n",
    "\n",
    "Give a brief overview of the data collected (e.g. count, fields, ...)"
   ]
  },
  {
   "cell_type": "code",
   "id": "48684760-3804-4ba0-a989-bbbf89383886",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T20:15:37.291581Z",
     "start_time": "2025-06-15T20:15:37.269290Z"
    }
   },
   "source": [
    "# TODO\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(songs)\n",
    "print(df.head())\n",
    "print(f\"\\nEs wurden {len(df)} Songs gesammelt mit den Feldern: {list(df.columns)}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Title                              Artist\n",
      "0         Ordinary                         Alex Warren\n",
      "1      What I Want  Morgan Wallen Featuring Tate McRae\n",
      "2     Just In Case                       Morgan Wallen\n",
      "3           Luther                Kendrick Lamar & SZA\n",
      "4  I'm The Problem                       Morgan Wallen\n",
      "\n",
      "Es wurden 100 Songs gesammelt mit den Feldern: ['Title', 'Artist']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "6517c66d-3f57-4da9-b3cd-db55c85585b3",
   "metadata": {},
   "source": [
    "## Save the Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "03309800-94f3-4529-bb22-3a44a0fb5242",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T20:15:56.354140Z",
     "start_time": "2025-06-15T20:15:56.326228Z"
    }
   },
   "source": [
    "# TODO\n",
    "df.to_csv('songArtist.csv', index=False)\n",
    "print(\"Daten wurden in 'songArtist.csv' gespeichert.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daten wurden in 'songArtist.csv' gespeichert.\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
